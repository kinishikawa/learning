{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture_chap4_exercise_master.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/m6650/DL/blob/master/lecture_chap4_exercise_master.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "AqfYyM538sB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 第4回講義 演習"
      ]
    },
    {
      "metadata": {
        "id": "gGWzWq1a8sB6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 課題1. ロジスティック回帰の実装と学習"
      ]
    },
    {
      "metadata": {
        "id": "igKa2g8q8sB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "b9a9345e-3747-47cd-d667-cd1d7fe18a87"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1234)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAxW-V9u8sB-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. シグモイド関数とその微分"
      ]
    },
    {
      "metadata": {
        "id": "hZgr0V888sCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "8b73894a-9ff2-466c-edfd-f83f550a2f5c"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def deriv_sigmoid(x):\n",
        "    return sigmoid(x) *(1-sigmoid(x))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b3z6VIHm8sCE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. データセットの設定と重みの定義"
      ]
    },
    {
      "metadata": {
        "id": "D2_8JwCb8sCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "d69a486e-a4a5-4446-8ae0-00a4a146b7fe"
      },
      "cell_type": "code",
      "source": [
        "# OR\n",
        "train_X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
        "train_y = np.array([[1], [1], [0], [1]])\n",
        "test_X, test_y = train_X, train_y\n",
        "\n",
        "# weights\n",
        "W = np.random.uniform(low=-0.08, high=0.08, size=(2, 1)).astype('float32')\n",
        "b = np.zeros(1).astype('float32')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Blo79uV98sCI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. train関数とtest関数"
      ]
    },
    {
      "metadata": {
        "id": "sl_jX57w8sCK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### 誤差関数\n",
        "* 負の対数尤度関数 (Negative Loglikelihood Function）\n",
        "* 交差エントロピー誤差関数ともいう\n",
        "\n",
        "$$ E ( {\\bf \\theta} ) =  -\\sum^N_{i=1} \\left[ t_i \\log y ({\\bf x}_i ; {\\bf \\theta}) + (1 - t_i) \\log \\{ 1 - y ({\\bf x}_i ; {\\bf \\theta}) \\}\\right] $$"
      ]
    },
    {
      "metadata": {
        "id": "OAJ6stgi8sCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "96b484e2-c56f-4f29-84d9-2baa27848702"
      },
      "cell_type": "code",
      "source": [
        "def train(x, t, eps=1.0):\n",
        "    global W, b # to access variables that defined outside of this function.\n",
        "    \n",
        "    # Forward Propagation\n",
        "    y = sigmoid(np.matmul(x, W) + b)\n",
        "    \n",
        "    # Back Propagation (Cost Function: Negative Loglikelihood)\n",
        "    cost = np.sum(-t*np.log(y)-(1-t)*np.log(1-y))\n",
        "    delta = y-t\n",
        "    \n",
        "    # Update Parameters\n",
        "    dW = np.matmul(x.T, delta)\n",
        "    db = np.matmul(np.ones(len(x)), delta)\n",
        "    W = W - eps*dW\n",
        "    b = b - eps*db\n",
        "\n",
        "    return cost\n",
        "\n",
        "def test(x, t):\n",
        "    # Test Cost\n",
        "    y = sigmoid(np.matmul(x, W) + b)\n",
        "    cost = np.sum(-t*np.log(y)-(1-t)*np.log(1-y))\n",
        "    return cost, y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q2u9_P4b8sCO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. 学習"
      ]
    },
    {
      "metadata": {
        "id": "A7umftFH8sCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0909f154-bcf2-490d-c5e7-51bddccd08f5"
      },
      "cell_type": "code",
      "source": [
        "# Epoch\n",
        "for epoch in range(1000):\n",
        "    # Online Learning\n",
        "    for x, y in zip(train_X, train_y):\n",
        "        cost = train(x[np.newaxis, :], y[np.newaxis, :])\n",
        "    cost, pred_y = test(test_X, test_y)\n",
        "\n",
        "print(pred_y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99799688]\n",
            " [0.99798893]\n",
            " [0.00499169]\n",
            " [0.99999998]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8syXfCJ58sCR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 課題2. 活性化関数とその微分の実装"
      ]
    },
    {
      "metadata": {
        "id": "Pn_VHuE28sCS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  1. シグモイド関数とその微分"
      ]
    },
    {
      "metadata": {
        "id": "03Dp1VaX8sCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "605fc8eb-1fa3-48c1-f673-4a4e05d7e73b"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def deriv_sigmoid(x):\n",
        "    return sigmoid(x)*(1 - sigmoid(x))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bI0UdgUH8sCW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. ソフトマックス関数とその微分"
      ]
    },
    {
      "metadata": {
        "id": "semmEnxZ8sCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "8e00fbd9-cc14-40bb-9c09-8cec858f4eac"
      },
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    exp_x = np.exp(x)\n",
        "    return exp_x/np.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "def deriv_softmax(x):\n",
        "    return softmax(x)*(1 - softmax(x))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ynXiDFe_8sCb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. tanh関数とその微分"
      ]
    },
    {
      "metadata": {
        "id": "W4CGqbLP8sCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "cbfdf4b0-63b9-4b9c-f17c-79d5b65b6342"
      },
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "\n",
        "def deriv_tanh(x):\n",
        "    return 1 - tanh(x)**2"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aFDbwrTx8sCe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 課題3. 多層パーセプトロンの実装と学習"
      ]
    },
    {
      "metadata": {
        "id": "V6zpgs0c8sCf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. データセットの設定と重みの定義"
      ]
    },
    {
      "metadata": {
        "id": "VKT7lCEr8sCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "7fdc3898-f543-47cf-ee68-9572fa22721f"
      },
      "cell_type": "code",
      "source": [
        "# XOR\n",
        "train_X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
        "train_y = np.array([[1], [1], [0], [0]])\n",
        "test_X, test_y = train_X, train_y\n",
        "\n",
        "# Layer1 weights\n",
        "W1 = np.random.uniform(low=-0.08, high=0.08, size=(2, 3)).astype('float32')\n",
        "b1 = np.zeros(3).astype('float32')\n",
        "\n",
        "# Layer2 weights\n",
        "W2 = np.random.uniform(low=-0.08, high=0.08, size=(3, 1)).astype('float32')\n",
        "b2 = np.zeros(1).astype('float32')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "myhfdBfg8sCj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.train関数とtest関数"
      ]
    },
    {
      "metadata": {
        "id": "MbjGfMro8sCl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### 誤差関数\n",
        "* 負の対数尤度関数 (Negative Loglikelihood Function）\n",
        "* 交差エントロピー誤差関数ともいう\n",
        "\n",
        "$$ E ( {\\bf \\theta} ) =  -\\sum^N_{i=1} \\left[ t_i \\log y ({\\bf x}_i ; {\\bf \\theta}) + (1 - t_i) \\log \\{ 1 - y ({\\bf x}_i ; {\\bf \\theta}) \\}\\right] $$"
      ]
    },
    {
      "metadata": {
        "id": "bfHRUrxE8sCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "702fc3e8-fd51-4a22-c45f-543689b202ca"
      },
      "cell_type": "code",
      "source": [
        "def train(x, t, eps=1.0):\n",
        "    global W1, b1, W2, b2 # to access variables that defined outside of this function.\n",
        "    \n",
        "    # Forward Propagation Layer1\n",
        "    u1 = np.matmul(x, W1) + b1\n",
        "    z1 = sigmoid(u1)\n",
        "    \n",
        "    # Forward Propagation Layer2\n",
        "    u2 = np.matmul(z1, W2) + b2\n",
        "    z2 = sigmoid(u2)\n",
        "    \n",
        "    # Back Propagation (Cost Function: Negative Loglikelihood)\n",
        "    y = z2\n",
        "    cost = np.sum(-t*np.log(y) - (1 - t)*np.log(1 - y))\n",
        "    delta_2 = y - t # Layer2 delta\n",
        "    delta_1 = deriv_sigmoid(u1) * np.matmul(delta_2, W2.T) # Layer1 delta\n",
        "\n",
        "    # Update Parameters Layer1\n",
        "    dW1 = np.matmul(x.T, delta_1)\n",
        "    db1 = np.matmul(np.ones(len(x)), delta_1)\n",
        "    W1 = W1 - eps*dW1\n",
        "    b1 = b1 - eps*db1\n",
        "    \n",
        "    # Update Parameters Layer2\n",
        "    dW2 = np.matmul(z1.T, delta_2)\n",
        "    db2 = np.matmul(np.ones(len(z1)), delta_2)\n",
        "    W2 = W2 - eps*dW2\n",
        "    b2 = b2 - eps*db2\n",
        "\n",
        "    return cost\n",
        "\n",
        "def test(x, t):\n",
        "    # Forward Propagation Layer1\n",
        "    u1 = np.matmul(x, W1) + b1\n",
        "    z1 = sigmoid(u1)\n",
        "    \n",
        "    # Forward Propagation Layer2\n",
        "    u2 = np.matmul(z1, W2) + b2\n",
        "    z2 = sigmoid(u2)\n",
        "    \n",
        "    y = z2\n",
        "    \n",
        "    # Test Cost\n",
        "    cost = np.sum(-t*np.log(y)-(1-t)*np.log(1-y))\n",
        "    return cost, y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51Tvz8en8sCq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. 学習"
      ]
    },
    {
      "metadata": {
        "id": "Ot4YUjpg8sCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e792ea97-21c4-462f-effc-e912206f525d"
      },
      "cell_type": "code",
      "source": [
        "# Epoch\n",
        "for epoch in range(2000):\n",
        "    # Online Learning\n",
        "    for x, y in zip(train_X, train_y):\n",
        "        cost = train(x[np.newaxis, :], y[np.newaxis, :])\n",
        "    cost, pred_y = test(test_X, test_y)\n",
        "\n",
        "print(pred_y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99788042]\n",
            " [0.99785468]\n",
            " [0.00182329]\n",
            " [0.0034414 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iYOw5BJ-87pg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 課題. MNISTデータセットを多層パーセプトロン(MLP)で学習せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意\n",
    "- homework関数を完成させて提出してください\n",
    "    - 訓練データはtrain_X, train_y, テストデータはtest_Xで与えられます\n",
    "    - train_Xとtrain_yをtrain_X, train_yとvalid_X, valid_yに分けるなどしてモデルを学習させてください\n",
    "    - test_Xに対して予想ラベルpred_yを作り, homework関数の戻り値としてください\\\n",
    "- pred_yのtest_yに対する精度(F値)で評価します\n",
    "- 全体の実行時間がiLect上で60分を超えないようにしてください\n",
    "- homework関数の外には何も書かないでください (必要なものは全てhomework関数に入れてください)\n",
    "- 解答提出時には Answer Cell の内容のみを提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MLPの実装にTensorflowなどのライブラリを使わないでください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ヒント\n",
    "- 出力yはone-of-k表現\n",
    "- 最終層の活性化関数はソフトマックス関数, 誤差関数は多クラス交差エントロピー\n",
    "- 最終層のデルタは教科書参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルのhomework関数を完成させて提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "ilect": {
     "is_homework": true
    }
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Layer\n",
    "    class Layer:\n",
    "        # Constructor\n",
    "        def __init__(self, in_dim, out_dim, function, deriv_function):\n",
    "            self.W = np.random.uniform(low=-0.08, high=0.08,\n",
    "                                       size=(in_dim, out_dim))\n",
    "            self.b = np.zeros(out_dim)\n",
    "            self.function = function\n",
    "            self.deriv_function = deriv_function\n",
    "            self.u = None\n",
    "            self.delta = None\n",
    "\n",
    "        # Forward Propagation\n",
    "        def f_prop(self, x):\n",
    "            self.u = np.dot(x, self.W) + self.b\n",
    "            self.z = self.function(self.u)\n",
    "            return self.z\n",
    "\n",
    "        # Back Propagation\n",
    "        def b_prop(self, delta, W):\n",
    "            self.delta = self.deriv_function(self.u)*np.dot(delta, W.T)\n",
    "            return self.delta\n",
    "\n",
    "    # Forward Propagation\n",
    "    def f_props(layers, x):\n",
    "        z = x\n",
    "        for layer in layers:\n",
    "            z = layer.f_prop(z)\n",
    "        return z\n",
    "\n",
    "    # Back Propagation\n",
    "    def b_props(layers, delta):\n",
    "        for i, layer in enumerate(layers[::-1]):\n",
    "            if i == 0:\n",
    "                layer.delta = delta\n",
    "            else:\n",
    "                delta = layer.b_prop(delta, _W)\n",
    "            _W = layer.W\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def deriv_sigmoid(x):\n",
    "        return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "    def softmax(x):\n",
    "        tem = np.exp(x)\n",
    "        return tem/np.sum(tem, axis=1)[:, np.newaxis]\n",
    "\n",
    "    def deriv_softmax(x):\n",
    "        return softmax(x)*(np.ones(x.shape) - softmax(x))\n",
    "\n",
    "    def tanh(x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def deriv_tanh(x):\n",
    "        return 1 - tanh(x)**2\n",
    "\n",
    "    layers = [\n",
    "        Layer(784, 200, sigmoid, deriv_sigmoid),\n",
    "        Layer(200, 200, sigmoid, deriv_sigmoid),\n",
    "        Layer(200, 10, softmax, deriv_softmax)\n",
    "    ]\n",
    "\n",
    "    def train(X, d, eps=0.1):\n",
    "        # Forward Propagation\n",
    "        y = f_props(layers, X)\n",
    "\n",
    "        # Cost Function & Delta\n",
    "        cost = - np.sum(d*np.log(y))\n",
    "        delta = y - d\n",
    "\n",
    "        # Back Propagation\n",
    "        b_props(layers, delta)\n",
    "\n",
    "        # Update Parameters\n",
    "        z = X\n",
    "        for i, layer in enumerate(layers):\n",
    "            dW = np.dot(z.T, layer.delta)\n",
    "            db = np.dot(np.ones(len(z)), layer.delta)\n",
    "\n",
    "            layer.W = layer.W - eps*dW\n",
    "            layer.b = layer.b - eps*db\n",
    "\n",
    "            if i != len(layers) - 1:\n",
    "                z = layer.z\n",
    "        # Train Cost\n",
    "        y = f_props(layers, X)\n",
    "        cost = - np.sum(d*np.log(y))\n",
    "\n",
    "        return cost\n",
    "\n",
    "    def valid(X, d):\n",
    "        # Test Cost\n",
    "        y = f_props(layers, X)\n",
    "        cost = - np.sum(d*np.log(y))\n",
    "        return cost, y\n",
    "\n",
    "    def test(X):\n",
    "        # Test Cost\n",
    "        y = f_props(layers, X)\n",
    "        return y\n",
    "\n",
    "    train_y = np.eye(10)[train_y]\n",
    "\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y,\n",
    "                                                          test_size=0.2,\n",
    "                                                          random_state=42)\n",
    "\n",
    "    # Epoch\n",
    "    for epoch in range(2):\n",
    "        # Online Learning\n",
    "        train_X, train_y = shuffle(train_X, train_y)\n",
    "        for x, y in zip(train_X, train_y):\n",
    "            cost = train(x[np.newaxis, :], y[np.newaxis, :], eps=0.1)\n",
    "\n",
    "        cost, pred_y = valid(valid_X, valid_y)\n",
    "\n",
    "    pred_y = np.argmax(test(test_X), axis=1)\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 以下のvalidate_homework関数を用いてエラーが起きないか動作確認をして下さい。\n",
    "- 提出に際して、 以下のscore_homework関数で60分で実行が終わることを確認して下さい。\n",
    "- 評価は以下のscore_homework関数で行われますが、random_stateの値は変更されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checker Cell (for student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "ilect": {
     "course_id": 4,
     "course_rank": 4,
     "is_evaluation": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                               mnist.target.astype('int32'), random_state=42)\n",
    "\n",
    "    mnist_X = mnist_X / 255.0\n",
    "\n",
    "    return train_test_split(mnist_X, mnist_y,\n",
    "                test_size=0.2,\n",
    "                random_state=42)\n",
    "\n",
    "def validate_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "\n",
    "    # validate for small dataset\n",
    "    train_X_mini = train_X[:100]\n",
    "    train_y_mini = train_y[:100]\n",
    "    test_X_mini = test_X[:100]\n",
    "    test_y_mini = test_y[:100]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "    print(f1_score(test_y_mini, pred_y, average='macro'))\n",
    "\n",
    "def score_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    pred_y = homework(train_X, train_y, test_X)\n",
    "    print(f1_score(test_y, pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_homework()\n",
    "# score_homework()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
